{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95940400",
   "metadata": {},
   "source": [
    "# Instructions for Use\n",
    "## 1) Download XLSX files for the indicator(s) and upload them to the appropriate indicator folder(s) in the [parent folder](https://drive.google.com/drive/folders/1ikgu5-ArNq0tqLZM_0oXBpi-x_kBlVn8).\n",
    "## 2) Open each file in Drive, click File > Save as Google Sheets. Once created, delete the original XLSX file.\n",
    "## 3) Edit cell 4 with the indicator(s) and academic year(s) you wish to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b86e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To access your Google Drive file, share the file with jupyter-sheets@sps-warehouse.iam.gserviceaccount.com\n",
      "To access your Google files, share the file with jupyter-sheets@sps-warehouse.iam.gserviceaccount.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<sqlalchemy.engine.base.Connection at 0x1fdf6c13ca0>,\n",
       " <sqlalchemy.engine.cursor.LegacyCursorResult at 0x1fdfd68fb50>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from spswarehouse.warehouse import Warehouse\n",
    "from spswarehouse.googledrive import GoogleDrive\n",
    "from spswarehouse.googlesheets import GoogleSheets as gs\n",
    "from spswarehouse.table_utils import *\n",
    "\n",
    "Warehouse.execute(\"USE ROLE dataops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b560d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imports(indicator_list, academic_year, folder_map):\n",
    "    res = {}\n",
    "    for indicator in indicator_list:\n",
    "        d = {}\n",
    "        folder = folder_map[indicator]\n",
    "        file_list = GoogleDrive.ListFile({'q': f\"'{folder}' in parents\"}).GetList()\n",
    "\n",
    "        #filter for academic year if applicable\n",
    "        if academic_year != 'all':\n",
    "            file_list = [x for x in file_list if academic_year in x['title']]\n",
    "\n",
    "        #load in each file to a dataframe with file name as key\n",
    "        for f in file_list:\n",
    "            d[f['title']] = f['id']\n",
    "        \n",
    "        res[indicator] = d\n",
    "    return res\n",
    "\n",
    "def generate_subfolder_dict(folder):\n",
    "    folder_list = GoogleDrive.ListFile({'q': f\"'{folder}' in parents\"}).GetList()\n",
    "    d = {}\n",
    "    for f in folder_list:\n",
    "        d[f['title']] = f['id']\n",
    "    return d\n",
    "\n",
    "def pull_site_cds_codes():\n",
    "    query = \"\"\"\n",
    "    select distinct site_name,\n",
    "    state_site_id\n",
    "    from public.sites\n",
    "    where state = 'CA'\n",
    "    and state_site_id is not null\n",
    "    \"\"\"\n",
    "    \n",
    "    return Warehouse.read_sql(query)\n",
    "\n",
    "def generate_cds_list(state_cds):\n",
    "    df = pull_site_cds_codes()\n",
    "    return df.append(state_cds,ignore_index=True)\n",
    "\n",
    "def load_df_from_gs(fid):\n",
    "    return pd.DataFrame(gs.open_by_key(fid).sheet1.get_all_records(numericise_ignore=[1]))\n",
    "\n",
    "def load_and_filter_df(fileid, cds_df):\n",
    "    #load up the full table\n",
    "    df = load_df_from_gs(fileid)\n",
    "    print('Loaded in', len(df), 'records')\n",
    "    dx = pd.merge(cds_df, df, how='left', left_on='state_site_id', right_on='cds', copy=False)\n",
    "    print('Filtered down to', len(dx), 'records')\n",
    "    return dx.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f928dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these stay the same\n",
    "parent_folder = '1ikgu5-ArNq0tqLZM_0oXBpi-x_kBlVn8'\n",
    "state_cds = {'site_name':'State of California',\n",
    "            'state_site_id': '00000000000000'}\n",
    "\n",
    "#modify these as needed\n",
    "indicator_list = ['ela']\n",
    "academic_year = 'all' #specify year in YYYY format if want just one year, defualts to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49b34cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LindsayWestlake\\AppData\\Local\\Temp\\ipykernel_27676\\2101239522.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(state_cds,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#generate some intermediary things\n",
    "folder_map = generate_subfolder_dict(parent_folder)\n",
    "m = load_imports(indicator_list, academic_year, folder_map)\n",
    "cds_df = generate_cds_list(state_cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c45ff906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Filtering Records for ela\n",
      "Pulling records from export eladownload2022\n",
      "Loaded in 169237 records\n",
      "Filtered down to 107 records\n",
      "Pulling records from export eladownload2018\n",
      "Loaded in 148838 records\n",
      "Filtered down to 105 records\n",
      "Pulling records from export eladownload2019\n",
      "Loaded in 165532 records\n",
      "Filtered down to 107 records\n",
      "Pulling records from export elapratedownload2019\n",
      "Loaded in 155216 records\n",
      "Filtered down to 98 records\n",
      "Pulling records from export elapratedownload2018\n",
      "Loaded in 155032 records\n",
      "Filtered down to 105 records\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "#load each raw file from sheets and filter just for our sites + state\n",
    "filt = {}\n",
    "\n",
    "for indicator, dx in m.items():\n",
    "    print('Loading and Filtering Records for', indicator)\n",
    "    res = {}\n",
    "    for export, fileid in dx.items():\n",
    "        print('Pulling records from export', export)\n",
    "        res[export] = load_and_filter_df(fileid, cds_df)\n",
    "    \n",
    "    filt[indicator] = res\n",
    "    print('=========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2193c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading records for ela\n",
      "Uploading export eladownload2022\n",
      "state_dashboard_ca.eladownload2022 created\n",
      "107 rows to insert\n",
      "Inserted 107 rows to state_dashboard_ca.eladownload2022\n"
     ]
    }
   ],
   "source": [
    "#upload to warehouse\n",
    "schema_name = 'state_dashboard_ca'\n",
    "\n",
    "for indicator, dx in filt.items():\n",
    "    print('Uploading records for', indicator)\n",
    "    for export, df in dx.items():\n",
    "        print('Uploading export', export)\n",
    "        table_name = export\n",
    "        try:\n",
    "            Warehouse.execute(f\"SELECT 1 FROM {schema_name}.{table_name}\")\n",
    "        except:\n",
    "            create_sql = create_table_stmt(table_name, schema_name, dataframe=df, force_string=True)\n",
    "            Warehouse.execute(create_sql)\n",
    "            print(f\"{schema_name}.{table_name} created\")\n",
    "        \n",
    "        table_reflect = Warehouse.reflect(table_name, schema_name)\n",
    "        upload_to_warehouse(table_reflect, dataframe=df, force_string=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
